{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AmazonChallenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyansh-Kedia/AmazonChallenge/blob/master/AmazonChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH-T-vwNxkGI"
      },
      "source": [
        "# Add all imports here\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTXbrZ0Bx_4m",
        "outputId": "fe4e71a7-471c-435b-a9a1-390f45dea677"
      },
      "source": [
        "# Download dataset\n",
        "\n",
        "!wget https://s3-ap-southeast-1.amazonaws.com/he-public-data/dataset52a7b21.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-30 06:51:51--  https://s3-ap-southeast-1.amazonaws.com/he-public-data/dataset52a7b21.zip\n",
            "Resolving s3-ap-southeast-1.amazonaws.com (s3-ap-southeast-1.amazonaws.com)... 52.219.132.18\n",
            "Connecting to s3-ap-southeast-1.amazonaws.com (s3-ap-southeast-1.amazonaws.com)|52.219.132.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1061576029 (1012M) [binary/octet-stream]\n",
            "Saving to: ‘dataset52a7b21.zip’\n",
            "\n",
            "dataset52a7b21.zip  100%[===================>]   1012M  12.7MB/s    in 83s     \n",
            "\n",
            "2021-07-30 06:53:14 (12.3 MB/s) - ‘dataset52a7b21.zip’ saved [1061576029/1061576029]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tTfjKnPyHr1",
        "outputId": "976bf8d7-9316-4992-fc9e-96acb6764850"
      },
      "source": [
        "# Unzip the dataset\n",
        "\n",
        "!unzip dataset52a7b21.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dataset52a7b21.zip\n",
            "   creating: dataset/\n",
            "  inflating: dataset/train.csv       \n",
            "  inflating: dataset/sample_submission.csv  \n",
            "  inflating: dataset/test.csv        \n",
            "  inflating: dataset/.~lock.train.csv#  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNhbbZLV8Qlr",
        "outputId": "36c7e83d-2e60-43a6-b42f-7fef00874dd3"
      },
      "source": [
        "# Download nltk stopwords\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOnUgUclx_2R"
      },
      "source": [
        "# Import the dataset in pandas\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "df = pd.read_csv(\"dataset/train.csv\", low_memory=True, escapechar=\"\\\\\", quoting=csv.QUOTE_NONE)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNqXrG9_0VA3"
      },
      "source": [
        "# Add the column variables here\n",
        "\n",
        "TITLE = \"TITLE\"\n",
        "PRODUCT_ID = \"PRODUCT_ID\"\n",
        "DESCRIPTION = \"DESCRIPTION\"\n",
        "BULLET_POINTS = \"BULLET_POINTS\"\n",
        "BRAND = \"BRAND\"\n",
        "BROWSE_NODE_ID = \"BROWSE_NODE_ID\""
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27j793xDx_zd"
      },
      "source": [
        "# Load the doc\n",
        "def load_doc(df):\n",
        "  titles = ' '.join(df[TITLE].astype(str))\n",
        "  descriptions = ' '.join(df[DESCRIPTION].astype(str))\n",
        "  bullets = ' '.join(df[BULLET_POINTS].astype(str))\n",
        "\n",
        "  return (titles + descriptions + bullets)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t57SfV219MkS"
      },
      "source": [
        "# To remove html tags\n",
        "\n",
        "def cleanhtml(raw_html):\n",
        "  cleanr = re.compile('<.*?>') # replace with re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});') for more strictness\n",
        "  cleantext = re.sub(cleanr, '', raw_html)\n",
        "  return cleantext"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JAUkgHEx_w2"
      },
      "source": [
        "def clean_doc(doc):\n",
        "  doc = cleanhtml(doc)\n",
        "  tokens = doc.split() # Add delimiter if needed\n",
        "\n",
        "  punctuations = str.maketrans('','', string.punctuation)\n",
        "\n",
        "  tokens = [w.translate(punctuations) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "\n",
        "  return tokens\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F8fE0Oix_uX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e7490f-ab9c-4240-bb84-835cfe6d2d30"
      },
      "source": [
        "# This is just created to test the above functions\n",
        "\n",
        "tokens = clean_doc('testing this for the use case <p>this should also be tested</p> <br>test this also breaking</br> <h1>and test heading too</h1>')\n",
        "print(tokens)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['testing', 'use', 'case', 'also', 'tested', 'test', 'also', 'breaking', 'test', 'heading']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSdzjJ1kx_rl"
      },
      "source": [
        "# Get cleaned document from here\n",
        "\n",
        "loaded = load_doc(df.head(2000))\n",
        "tokens = clean_doc(loaded)\n",
        "\n",
        "# print(tokens)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttnDw3-wx_pA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}